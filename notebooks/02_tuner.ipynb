{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the images to a range of 0 to 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Reshape the images to include the channel dimension\n",
    "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
    "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "  x = inputs\n",
    "  for i in range(hp.Int('conv_blocks', 3, 5, default=3)):\n",
    "    filters = hp.Int('filters_' + str(i), 16, 128, step=16)\n",
    "    for _ in range(2):\n",
    "      x = tf.keras.layers.Convolution2D(\n",
    "        filters, kernel_size=(3, 3), padding='same')(x)\n",
    "      x = tf.keras.layers.BatchNormalization()(x)\n",
    "      x = tf.keras.layers.ReLU()(x)\n",
    "    if hp.Choice('pooling_' + str(i), ['avg', 'max']) == 'max':\n",
    "      x = tf.keras.layers.MaxPool2D()(x)\n",
    "    else:\n",
    "      x = tf.keras.layers.AvgPool2D()(x)\n",
    "  x = tf.keras.layers.GlobalAvgPool2D()(x)\n",
    "  x = tf.keras.layers.Dense(hp.Int('hidden_size', 30, 100, step=10, default=50),activation='relu')(x)\n",
    "  x = tf.keras.layers.Dropout(hp.Float('dropout', 0, 0.5, step=0.1, default=0.5))(x)\n",
    "  outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "  model = tf.keras.Model(inputs, outputs)\n",
    "  model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(\n",
    "      hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')),\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "\n",
    "def model_builder_v2(hp):\n",
    "  inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "  x = inputs\n",
    "  for i in range(hp.Int('conv_blocks', 3, 5, default=3)):\n",
    "    filters = hp.Int('filters_' + str(i), 16, 128, step=16)\n",
    "    dropout = hp.Float('dropout_' + str(i), 0, 0.8)\n",
    "    for _ in range(2):\n",
    "      x = tf.keras.layers.Convolution2D(filters, kernel_size=(3, 3), padding='same')(x)\n",
    "      x = tf.keras.layers.SpatialDropout2D(dropout)(x)\n",
    "      x = tf.keras.layers.BatchNormalization()(x)\n",
    "      x = tf.keras.layers.ReLU()(x)\n",
    "    if hp.Choice('pooling_' + str(i), ['avg', 'max']) == 'max':\n",
    "      x = tf.keras.layers.MaxPool2D((2, 2))(x)\n",
    "    else:\n",
    "      x = tf.keras.layers.AvgPool2D((2, 2))(x)\n",
    "  x = tf.keras.layers.Conv2D(10, (1, 1), padding=\"same\",  activation='softmax')(x)\n",
    "  outputs = tf.keras.layers.GlobalAvgPool2D()(x)\n",
    "  model = tf.keras.Model(inputs, outputs)\n",
    "  \n",
    "  optimizers = {\n",
    "    'adamW': tf.keras.optimizers.AdamW,\n",
    "    'adam': tf.keras.optimizers.Adam,\n",
    "    'nadam': tf.keras.optimizers.Nadam\n",
    "  }\n",
    "  optimizer_name = hp.Choice('optimizer', list(optimizers.keys()))\n",
    "  lr = hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')\n",
    "  model.compile(\n",
    "    optimizer=optimizers[optimizer_name](learning_rate=lr),\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "\n",
    "def only_optimizer(hp):\n",
    "  model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.SpatialDropout2D(0.25), \n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\",  activation='relu'),\n",
    "        tf.keras.layers.SpatialDropout2D(0.25), \n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\",  activation='relu'),\n",
    "        tf.keras.layers.SpatialDropout2D(0.25), \n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), padding=\"same\",  activation='relu'),\n",
    "        tf.keras.layers.SpatialDropout2D(0.25), \n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(10, (1, 1), padding=\"same\",  activation='softmax'), \n",
    "        tf.keras.layers.GlobalAvgPool2D(),\n",
    "    ], name=\"global_avg\")\n",
    "  \n",
    "  lr = hp.Float('learning_rate', 1e-4, 1e-2, sampling='log', default=0.001)\n",
    "  beta_1 = hp.Float('beta_1', 0.7, 0.99, sampling='log', default=0.9)\n",
    "  beta_2 = hp.Float('beta_2', 0.9, 0.999, sampling='log', default=0.999)\n",
    "  ema_momentum = hp.Float('ema_momentum', 0.9, 0.999, default=0.99)\n",
    "  model.compile(\n",
    "    optimizer=tf.keras.optimizers.Nadam(\n",
    "      learning_rate=lr,\n",
    "      beta_1=beta_1,\n",
    "      beta_2=beta_2,\n",
    "      use_ema=True,\n",
    "      ema_momentum=ema_momentum),\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  return model\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner = kt.Hyperband(model_builder_v2,\n",
    "#                      objective='val_accuracy',\n",
    "#                      max_epochs=10,\n",
    "#                      factor=3,\n",
    "#                      directory='my_dir',\n",
    "#                      project_name='fashion_mnist_kt')\n",
    "tuner = kt.BayesianOptimization(\n",
    "    only_optimizer,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=30,\n",
    "    directory=\"optimizer_search\",\n",
    "    project_name='global_avg_model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_images, train_labels, epochs=3, validation_split=0.2, callbacks=[stop_early])\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get the search results\n",
    "results = tuner.oracle.get_best_trials(num_trials=10)\n",
    "\n",
    "# Prepare a DataFrame to store results\n",
    "results_data = []\n",
    "for trial in results:\n",
    "    trial_data = trial.hyperparameters.values\n",
    "    trial_data['score'] = trial.score\n",
    "    results_data.append(trial_data)\n",
    "\n",
    "df = pd.DataFrame(results_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot for units vs. accuracy\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['learning_rate'], df['score'])\n",
    "plt.xlabel('learning_rate')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Units vs. Validation Accuracy')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(train_images, train_labels, epochs=30, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
